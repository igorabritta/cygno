{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Analysis over the Clusters\n",
    "## Loading libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cygnus_lib as cy\n",
    "import toolslib as tl\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from iDBSCAN import iDBSCAN\n",
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "\n",
    "from time import time\n",
    "from ast import literal_eval\n",
    "from math import degrees\n",
    "from math import radians\n",
    "from toolslib import colorbar\n",
    "\n",
    "\n",
    "## font definition\n",
    "%matplotlib inline\n",
    "plt.rcParams['font.family'] = 'sans-serif'\n",
    "plt.rcParams['font.sans-serif'] = ['Bitstream Vera Sans']\n",
    "plt.rcParams['font.serif'] = ['Bitstream Vera Sans']\n",
    "cy.set_atlas_style('large')\n",
    "\n",
    "sns.set_context('poster')\n",
    "sns.set_style('white')\n",
    "sns.set_color_codes()\n",
    "plot_kwds = {'alpha' : 0.5, 's' : 30, 'linewidths':0}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variables definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_resolution = y_resolution = 2048\n",
    "rescale      = 512\n",
    "scale        = int(x_resolution/rescale)\n",
    "pixelscale   = 55e-3             #55e-3 for Orange ------ 0.125 for lemonn mm/pixel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data\n",
    "\n",
    "List contain:\n",
    "\n",
    "[0 - Run number, 1 - Image Number, 2 - Tag of the cluster, 3 - Pixel X position, 4 - Pixel Y position, 5 - Light in the pixel, 6 - Pedestal in the pixel]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tic=time()\n",
    "#------------------- Loading File ------------------------------#\n",
    "directory = (\"./data/\")          # Directory of the output file\n",
    "filename  = (\"toEff_L\")            # Name of the output file\n",
    "extension = (\".csv\")             # Extension of the output file\n",
    "dataout   = directory + filename + extension # Full path of the output file\n",
    "\n",
    "dt        = {'Run': np.int64, 'Image': np.int64, 'Tag': np.object, 'X': np.object, \n",
    "             'Y': np.object, 'Light': np.object, 'Pedestal': np.object}\n",
    "colhead   = [\"Run\",\"Image\",\"Tag\",\"X\",\"Y\",\"Light\",\"Pedestal\"]\n",
    "dfl       = pd.read_csv(dataout,dtype=dt)\n",
    "\n",
    "dfl.loc[:,'X']        = dfl.loc[:,'X'].apply(literal_eval)\n",
    "dfl.loc[:,'Y']        = dfl.loc[:,'Y'].apply(literal_eval)\n",
    "dfl.loc[:,'Light']    = dfl.loc[:,'Light'].apply(literal_eval)\n",
    "dfl.loc[:,'Pedestal'] = dfl.loc[:,'Pedestal'].apply(literal_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#------------------- Loading File ------------------------------#\n",
    "directory = (\"./data/\")          # Directory of the output file\n",
    "filename  = (\"toEff_M\")            # Name of the output file\n",
    "extension = (\".csv\")             # Extension of the output file\n",
    "dataout   = directory + filename + extension # Full path of the output file\n",
    "\n",
    "dt        = {'Run': np.int64, 'Image': np.int64, 'Tag': np.object, 'X': np.object, \n",
    "             'Y': np.object, 'Light': np.object, 'Pedestal': np.object}\n",
    "colhead   = [\"Run\",\"Image\",\"Tag\",\"X\",\"Y\",\"Light\",\"Pedestal\"]\n",
    "dfm       = pd.read_csv(dataout,dtype=dt)\n",
    "\n",
    "dfm.loc[:,'X']        = dfm.loc[:,'X'].apply(literal_eval)\n",
    "dfm.loc[:,'Y']        = dfm.loc[:,'Y'].apply(literal_eval)\n",
    "dfm.loc[:,'Light']    = dfm.loc[:,'Light'].apply(literal_eval)\n",
    "dfm.loc[:,'Pedestal'] = dfm.loc[:,'Pedestal'].apply(literal_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading time: 0.18\n"
     ]
    }
   ],
   "source": [
    "#------------------- Loading File ------------------------------#\n",
    "directory = (\"./data/\")          # Directory of the output file\n",
    "filename  = (\"toEff_S\")            # Name of the output file\n",
    "extension = (\".csv\")             # Extension of the output file\n",
    "dataout   = directory + filename + extension # Full path of the output file\n",
    "\n",
    "dt        = {'Run': np.int64, 'Image': np.int64, 'Tag': np.object, 'X': np.object, \n",
    "             'Y': np.object, 'Light': np.object, 'Pedestal': np.object}\n",
    "colhead   = [\"Run\",\"Image\",\"Tag\",\"X\",\"Y\",\"Light\",\"Pedestal\"]\n",
    "dfs       = pd.read_csv(dataout,dtype=dt)\n",
    "\n",
    "dfs.loc[:,'X']        = dfs.loc[:,'X'].apply(literal_eval)\n",
    "dfs.loc[:,'Y']        = dfs.loc[:,'Y'].apply(literal_eval)\n",
    "dfs.loc[:,'Light']    = dfs.loc[:,'Light'].apply(literal_eval)\n",
    "dfs.loc[:,'Pedestal'] = dfs.loc[:,'Pedestal'].apply(literal_eval)\n",
    "\n",
    "toc = time()\n",
    "print(\"Loading time: %.2f\" % ((toc-tic)/60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = [dfl, dfm, dfs]\n",
    "df = pd.concat(frames, ignore_index = True)\n",
    "\n",
    "del frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pointInsideCircle(Px, Py, Cx = 1024, Cy = 1024, R = 900):\n",
    "    Hx = np.zeros(4,dtype=float)\n",
    "    Hy = np.zeros(4,dtype=float)\n",
    "    \n",
    "    Hx[0] = np.min(Px)\n",
    "    Hy[0] = Py[np.argmin(Px)]\n",
    "    \n",
    "    Hx[1] = np.max(Px)\n",
    "    Hy[1] = Py[np.argmax(Px)]\n",
    "      \n",
    "    Hx[2] = np.min(Py)\n",
    "    Hy[2] = Px[np.argmin(Py)]\n",
    "    \n",
    "    Hx[3] = np.max(Py)\n",
    "    Hy[3] = Px[np.argmax(Py)]\n",
    "    \n",
    "    out = np.ones(4, dtype=bool)\n",
    "    for i in range(0,len(Hx)):\n",
    "        \n",
    "        teste = np.sqrt((Hx[i]-Cx)**2 + (Hy[i]-Cy)**2)\n",
    "        if teste < R:\n",
    "            out[i] = True\n",
    "        else:\n",
    "            out[i] = False\n",
    "\n",
    "    result = np.all(out)\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create background noise from mean + sigma of the run\n",
      "Index Long track: 12\n",
      "Create background noise from mean + sigma of the run\n",
      "Index Long track: 17\n",
      "Create background noise from mean + sigma of the run\n",
      "Index Long track: 16\n",
      "Create background noise from mean + sigma of the run\n",
      "Index Long track: 19\n",
      "Create background noise from mean + sigma of the run\n",
      "Index Long track: 10\n",
      "Create background noise from mean + sigma of the run\n",
      "Index Long track: 0\n",
      "Create background noise from mean + sigma of the run\n",
      "Index Long track: 0\n",
      "Create background noise from mean + sigma of the run\n",
      "Index Long track: 11\n",
      "Create background noise from mean + sigma of the run\n",
      "Index Long track: 8\n",
      "Create background noise from mean + sigma of the run\n",
      "Index Long track: 10\n"
     ]
    }
   ],
   "source": [
    "# List to salve all simulated images and informations\n",
    "clutruth   = []\n",
    "truth      = []\n",
    "tag        = []\n",
    "pedestal   = 99\n",
    "\n",
    "flag_angle = False\n",
    "flag_bkg   = False\n",
    "flag_plt   = False\n",
    "\n",
    "runI  = [494]\n",
    "nRi   = 0\n",
    "\n",
    "nfigures   = 10\n",
    "\n",
    "if flag_bkg == False:\n",
    "    fileoutm = (\"./data/run%d_mean.h5\" % (runI[nRi]))\n",
    "    m_image = cy.read_image_h5(fileoutm)\n",
    "    fileouts = (\"./data/run%d_sigma.h5\" % (runI[nRi]))\n",
    "    s_image = cy.read_image_h5(fileouts)\n",
    "\n",
    "for jj in range(0,nfigures):\n",
    "    #Background\n",
    "    \n",
    "    if flag_bkg == True:\n",
    "        dataSelection = 'LAB'\n",
    "        cleImg = [4,5,7,9,15]\n",
    "        iTr   = cleImg[np.random.randint(0, len(cleImg))]\n",
    "        imageOri = cy.swift_read_image_h5(cy.imageFile2FullPathCygnus(dataSelection, runI[0], iTr)) \n",
    "        titletext = \"I%d Run%d + one random long track\" % (iTr, runI[0])\n",
    "        print(\"Using I%d Run%d as background noise\" % (iTr, runI[0]))\n",
    "        \n",
    "    else:\n",
    "        # To remove any NaN\n",
    "        s_image[np.isnan(s_image)] = np.mean(s_image[~np.isnan(s_image)])\n",
    "        m_image[np.isnan(m_image)] = np.mean(m_image[~np.isnan(m_image)])\n",
    "\n",
    "        m_image[m_image > 101] = np.mean(m_image[m_image < 101])\n",
    "        s_image[s_image > 4]   = np.mean(s_image[s_image < 4])\n",
    "\n",
    "        imageOri = np.random.normal(m_image,s_image,[2048,2048])\n",
    "        titletext = \"Inserting background noise\"\n",
    "        print(\"Create background noise from mean + sigma of the run\")\n",
    "            \n",
    "\n",
    "    #matrix = np.zeros([y_resolution,x_resolution],dtype=int) # Background\n",
    "    image    = np.copy(imageOri)\n",
    "\n",
    "    it       = -1 \n",
    "    \n",
    "    nSmall   = 0\n",
    "    nMedium  = 0\n",
    "    nLong    = 3\n",
    "    \n",
    "    fname  = np.str(nLong) + \"L\" + np.str(nMedium) + \"M\" + np.str(nSmall) + \"S\"\n",
    "\n",
    "    #rd       = np.concatenate([np.random.randint(0, dfl.shape[0],nLong),np.random.randint(11, 15 + 1,nMedium),\n",
    "    #                           np.random.randint(16, 20 + 1,nSmall)])\n",
    "    \n",
    "    rd       = np.concatenate([np.random.randint(0, dfl.shape[0],nLong),\n",
    "                               np.random.randint(dfl.shape[0], dfl.shape[0] + dfm.shape[0],nMedium),\n",
    "                               np.random.randint(dfl.shape[0] + dfm.shape[0],\n",
    "                                                 dfl.shape[0] + dfm.shape[0] + dfs.shape[0],nSmall)])\n",
    "    \n",
    "    for kk in range(0,nLong):\n",
    "        tag.append('l')\n",
    "    for kk in range(0,nMedium):\n",
    "        tag.append('m')\n",
    "    for kk in range(0,nSmall):\n",
    "        tag.append('s')\n",
    "        \n",
    "    for ind in rd:\n",
    "        it += 1\n",
    "        \n",
    "        if flag_angle == True:\n",
    "            angle             = radians(np.random.randint(0, 360 + 1))\n",
    "            #newX,newY         = tl.rotate(df.X[ind][0],df.Y[ind][0],df.X[ind],df.Y[ind],angle)\n",
    "            newX,newY         = tl.rotate(df.X[ind][0],df.Y[ind][0],df.X[ind],df.Y[ind],angle)\n",
    "            #newX,newY         = tl.rotate(0,0,df.X[ind],df.Y[ind],angle)\n",
    "            newX              = np.round(newX).astype(int)\n",
    "            newY              = np.round(newY).astype(int)\n",
    "\n",
    "            if np.min(newX) <= 0:\n",
    "                newX = newX +np.abs(np.min(newX))\n",
    "            if np.max(newX) >= 2047:\n",
    "                newX = newX - (np.abs(np.max(newX)) - 2047)\n",
    "\n",
    "            if np.min(newY) <= 0:\n",
    "                newY = newY +np.abs(np.min(newY))\n",
    "            if np.max(newY) >= 2047:\n",
    "                newY = newY - (np.abs(np.max(newY)) - 2047)\n",
    "        else:\n",
    "            newX = np.array(df.X[ind])\n",
    "            newY = np.array(df.Y[ind])\n",
    "\n",
    "        flag_inside = False\n",
    "        while (flag_inside == False):\n",
    "            addX = [np.random.randint(0, 2047 + 1 - np.max(newX)), -1*np.random.randint(0,np.min(newX) + 1)]\n",
    "            addY = [np.random.randint(0, 2047 + 1 - np.max(newY)), -1*np.random.randint(0,np.min(newY) + 1)]\n",
    "            mm = np.random.randint(0, 2)\n",
    "\n",
    "            newX              = newX+addX[mm]\n",
    "            newY              = newY+addY[mm]\n",
    "\n",
    "            flag_inside = pointInsideCircle(newX, newY, Cx = 1024, Cy = 1024, R = 900)\n",
    "        \n",
    "        Lp                = df[colhead[5]][ind]\n",
    "        image[newY,newX]  = (np.array(Lp)-pedestal) + image[newY,newX]\n",
    "        \n",
    "        infc = []\n",
    "        infc.append(jj)\n",
    "        infc.append(newX)\n",
    "        infc.append(newY)\n",
    "        infc.append(Lp)\n",
    "        infc.append(tag[it])\n",
    "        clutruth.append(infc)\n",
    "\n",
    "    if flag_plt == True:\n",
    "        fig = plt.figure(figsize=(15,15))\n",
    "        ax  = plt.gca()\n",
    "\n",
    "        iax = ax.imshow(image, cmap = \"viridis\", vmin = 85, vmax = 130)\n",
    "        ax.set_xlim(0,2047)\n",
    "        ax.set_ylim(2047,0)\n",
    "        ax.set_title(titletext)\n",
    "        colorbar(iax)\n",
    "        plt.show(block=False)\n",
    "        plt.close()\n",
    "\n",
    "    print(\"Index Long track: %d\" % (rd[0]))   \n",
    "    \n",
    "    inf = []\n",
    "    inf.append(image)\n",
    "    inf.append(jj)\n",
    "    truth.append(inf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# i2DBSCAN vs DBSCAN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################ analysis cards ################################\n",
    "nsigma       = 1         # numero di sigma sopra il piedistallo\n",
    "cimax        = 200       # valori del cut sull'imagine\n",
    "rescale      = 512       # binnagio finale immagine (deve essre un sottomultipli della 2**2 risluzione di partenza)\n",
    "minClose     = 2         # minimum cluser size (rebinne image)\n",
    "eps          = 5         # maximum distance for the cluster point\n",
    "maxClose     = 30000     # massima dimesione del clustr evita le scriche      \n",
    "Cmethod      = 'idbsc'    #'hdbs' # 'nccs' # 'dbsc' # 'idbsc'\n",
    "max_image_to_read = 60  # 0 all\n",
    "############### Inzializzazione varibili e costanti #################\n",
    "scale        = int(x_resolution/rescale)\n",
    "\n",
    "\n",
    "\n",
    "iterative    = 1         # number of iterations for the IDBSC\n",
    "vector_eps = [2.26, 3.5, 2.8, 6]\n",
    "vector_min_samples = [2, 28, 4, 2]\n",
    "cuts = [775, 150]\n",
    "\n",
    "\n",
    "# MAIN LOOP ON \n",
    "\n",
    "dataNaive    = [] # output data\n",
    "datai2DB     = [] # output data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pedestal mean: 99.63, sigma: 2.02, over th. (200) 1955\n",
      "Sigma mean: 3.23, sigma: 2.23, over th. (50) 2208\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.6/site-packages/ipykernel_launcher.py:19: RuntimeWarning: invalid value encountered in less\n",
      "/usr/lib/python3.6/site-packages/ipykernel_launcher.py:20: RuntimeWarning: invalid value encountered in less\n",
      "/usr/lib/python3.6/site-packages/ipykernel_launcher.py:21: RuntimeWarning: invalid value encountered in greater\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# load pedestal value generated by runs-pedestals.ipynb script\n",
    "# \n",
    "try:\n",
    "    fileoutm = (\"./data/run%d_mean.h5\" % (runI[nRi]))\n",
    "    m_image = cy.read_image_h5(fileoutm)\n",
    "    PedOverMax = m_image[m_image > cimax].size\n",
    "    print (\"Pedestal mean: %.2f, sigma: %.2f, over th. (%d) %d\" % \n",
    "       (m_image[m_image<cimax].mean(), \n",
    "        np.sqrt(m_image[m_image<cimax].var()), cimax,\n",
    "        (m_image>cimax).sum()))\n",
    "except:\n",
    "    print (\"No Pedestal file for run %s, run script runs-pedestals.ipynb\" % runI[nRi])\n",
    "    print (\"STOP\")\n",
    "try: \n",
    "    fileouts = (\"./data/run%d_sigma.h5\" % (runI[nRi]))\n",
    "    s_image = cy.read_image_h5(fileouts)\n",
    "    print (\"Sigma mean: %.2f, sigma: %.2f, over th. (50) %d\" % \n",
    "   (s_image[s_image<50].mean(), \n",
    "    np.sqrt(s_image[s_image<50].var()), \n",
    "    (s_image>50).sum()))\n",
    "except:\n",
    "    print (\"No Sigma file for run %s, run script runs-pedestals.ipynb\" % runI[nRi])\n",
    "    print (\"STOP\")\n",
    "\n",
    "#\n",
    "# Run by run init \n",
    "#\n",
    "th_image      = np.round(m_image + nsigma*s_image) # verficare con il np.round.... np.ceil\n",
    "th_image[:,:] = 102 # per imostare tutto a 101\n",
    "\n",
    "TrOk   = 0\n",
    "dCloseT= 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of clusters: 30\n",
      "Total ligth on all clusters: 30735165\n",
      "Total number of pixels on all clusters: 265120\n"
     ]
    }
   ],
   "source": [
    "# Truth\n",
    "tnumPixT = 0\n",
    "tnumCluT = len(clutruth)\n",
    "teneCluT = 0\n",
    "\n",
    "for it in range(0,len(truth)):\n",
    "    tnumPixT = tnumPixT + np.size(clutruth[it][1])\n",
    "    teneCluT = teneCluT + np.sum(clutruth[it][3])\n",
    "\n",
    "print(\"Total number of clusters: %d\" % (tnumCluT))\n",
    "print(\"Total ligth on all clusters: %d\" % (teneCluT))\n",
    "print(\"Total number of pixels on all clusters: %d\" % (tnumPixT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...Next EPS...2.222222% \n",
      "\n",
      "...Next EPS...4.444444% \n",
      "\n",
      "...Next EPS...6.666667% \n",
      "\n",
      "...Next EPS...8.888889% \n",
      "\n",
      "...Next EPS...11.111111% \n",
      "\n",
      "...Next EPS...13.333333% \n",
      "\n",
      "...Next EPS...15.555556% \n",
      "\n",
      "...Next EPS...17.777778% \n",
      "\n",
      "...Next EPS...20.000000% \n",
      "\n",
      "...Next EPS...22.222222% \n",
      "\n",
      "...Next EPS...24.444444% \n",
      "\n",
      "...Next EPS...26.666667% \n",
      "\n",
      "...Next EPS...28.888889% \n",
      "\n",
      "...Next EPS...31.111111% \n",
      "\n",
      "...Next EPS...33.333333% \n",
      "\n",
      "...Next EPS...35.555556% \n",
      "\n",
      "...Next EPS...37.777778% \n",
      "\n",
      "...Next EPS...40.000000% \n",
      "\n",
      "...Next EPS...42.222222% \n",
      "\n",
      "...Next EPS...44.444444% \n",
      "\n",
      "...Next EPS...46.666667% \n",
      "\n",
      "...Next EPS...48.888889% \n",
      "\n",
      "...Next EPS...51.111111% \n",
      "\n",
      "...Next EPS...53.333333% \n",
      "\n",
      "...Next EPS...55.555556% \n",
      "\n",
      "...Next EPS...57.777778% \n",
      "\n",
      "...Next EPS...60.000000% \n",
      "\n",
      "...Next EPS...62.222222% \n",
      "\n",
      "...Next EPS...64.444444% \n",
      "\n",
      "...Next EPS...66.666667% \n",
      "\n",
      "...Next EPS...68.888889% \n",
      "\n",
      "...Next EPS...71.111111% \n",
      "\n",
      "...Next EPS...73.333333% \n",
      "\n",
      "...Next EPS...75.555556% \n",
      "\n",
      "...Next EPS...77.777778% \n",
      "\n",
      "...Next EPS...80.000000% \n",
      "\n",
      "...Next EPS...82.222222% \n",
      "\n",
      "...Next EPS...84.444444% \n",
      "\n",
      "...Next EPS...86.666667% \n",
      "\n",
      "...Next EPS...88.888889% \n",
      "\n",
      "...Next EPS...91.111111% \n",
      "\n",
      "...Next EPS...93.333333% \n",
      "\n",
      "...Next EPS...95.555556% \n",
      "\n",
      "...Next EPS...97.777778% \n",
      "\n"
     ]
    }
   ],
   "source": [
    "flag_naive = False\n",
    "\n",
    "vectoreps = np.concatenate([list(np.linspace(0.1,4,30)),list(np.linspace(5,10,5)),list(np.linspace(10,50,10))])\n",
    "vectorminp = np.round(np.concatenate([list(np.linspace(1,10,10)),list(np.linspace(15,150,10)),list(np.linspace(160,240,20))]))\n",
    "                      \n",
    "tamX = len(vectoreps)\n",
    "tamY = len(vectorminp)\n",
    "\n",
    "info = []\n",
    "tnumPix = np.zeros([tamX,tamY],dtype=int)\n",
    "tnumClu = np.zeros([tamX,tamY],dtype=int)\n",
    "teneClu = np.zeros([tamX,tamY],dtype=int)\n",
    "\n",
    "aux0 = -1\n",
    "\n",
    "for eps in vectoreps:\n",
    "    aux0 +=1\n",
    "    aux1 = -1\n",
    "    for minp in vectorminp:\n",
    "        aux1 +=1\n",
    "\n",
    "        for it in range(0,len(truth)):\n",
    "            edges_image     = (truth[it][0] > th_image) & (truth[it][0] < cimax)\n",
    "            rebin_image     = cy.rebin(truth[it][0], (rescale, rescale))\n",
    "            rebin_th_image  = cy.rebin(th_image, (rescale, rescale))\n",
    "            edges           = (rebin_image > rebin_th_image) & (rebin_image < cimax)         \n",
    "            points          = np.array(np.nonzero(edges)).T.astype(float)\n",
    "\n",
    "            #clusters = iDBSCAN(iterative).fit(points)\n",
    "            vector_eps[1] = eps\n",
    "            vector_min_samples[1] = minp\n",
    "            \n",
    "            clusters = iDBSCAN(iterative = 1, vector_eps = vector_eps, vector_min_samples = vector_min_samples, cuts = cuts).fit(points)\n",
    "\n",
    "\n",
    "            n_clusters_  = len(set(clusters.labels_)) - (1 if -1 in clusters.labels_ else 0)\n",
    "\n",
    "            tnumClu[aux0,aux1] = tnumClu[aux0,aux1] + n_clusters_\n",
    "\n",
    "\n",
    "            for Ci in range (0, n_clusters_): # number of clusters found in the image\n",
    "                cluvar   = [] # cluster info\n",
    "                #print (\"Salving cluster %d from %d\" % (Ci,n_clusters_))\n",
    "                Xi, Yi, Is, Ib, tag = tl.cluInfo(clusters,points,Ci,truth[it][0],th_image,scale) # extract cluster information\n",
    "                # cluvar = [Run, Imag, Tag, X position, Y position, Light signal, Light pedestal]\n",
    "                cluvar.append(runI[nRi])\n",
    "                cluvar.append(clutruth[it][4])\n",
    "                cluvar.append(tag)\n",
    "                cluvar.append(Xi)\n",
    "                cluvar.append(Yi)\n",
    "                cluvar.append(Is)\n",
    "                cluvar.append(Ib)\n",
    "                datai2DB.append(cluvar) # save the cluster info in a List\n",
    "                tnumPix[aux0,aux1] = tnumPix[aux0,aux1] + np.size(Xi)\n",
    "                teneClu[aux0,aux1] = teneClu[aux0,aux1] + np.sum(Is)\n",
    "\n",
    "\n",
    "            if flag_naive == True:\n",
    "\n",
    "                naive    = iDBSCAN(iterative = 0, vector_eps = [2.6, 3.5, 2.8, 6], \n",
    "                                   vector_min_samples = [2, 30, 6, 2], cuts = cuts).fit(points)\n",
    "\n",
    "                n_clusters_n = len(set(naive.labels_)) - (1 if -1 in naive.labels_ else 0)\n",
    "                for Ci in range (0, n_clusters_n): # number of clusters found in the image\n",
    "                    cluvar   = [] # cluster info\n",
    "                    #print (\"Salving cluster %d from %d\" % (Ci,n_clusters_))\n",
    "                    Xi, Yi, Is, Ib, tag = tl.cluInfo(naive,points,Ci,truth[it][0],th_image,scale) # extract cluster information\n",
    "                    # cluvar = [Run, Imag, Tag, X position, Y position, Light signal, Light pedestal]\n",
    "                    cluvar.append(runI[nRi])\n",
    "                    cluvar.append(clutruth[it][4])\n",
    "                    cluvar.append(tag)\n",
    "                    cluvar.append(Xi)\n",
    "                    cluvar.append(Yi)\n",
    "                    cluvar.append(Is)\n",
    "                    cluvar.append(Ib)\n",
    "                    dataNaive.append(cluvar) # save the cluster info in a List\n",
    "\n",
    "    print (\"...Next EPS...%f%% \\n\" % (((aux0+1)/tamX)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make data.\n",
    "Xx = vectoreps\n",
    "Yy = vectorminp\n",
    "Xx, Yy = np.meshgrid(Xx, Yy)\n",
    "Z = teneClu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "azim = 180+45\n",
    "elev = 30\n",
    "un = 1000000\n",
    "\n",
    "fig = plt.figure(figsize = (12,8))\n",
    "ax  = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "ax.scatter(Yy.T,Xx.T, Z/un, c = 'r', marker = 'o')\n",
    "\n",
    "ax.set_xlabel('MinPoints',labelpad = 20, rotation=0)\n",
    "ax.set_ylabel('Eps',labelpad = 20)\n",
    "ax.set_zlabel('Total light in all clusters [M]', labelpad = 10, rotation = 90)\n",
    "ax.set_ylim(0,80)\n",
    "ax.set_xlim(0,300)\n",
    "ax.set_zlim(bottom = 0)\n",
    "ax.view_init(elev = elev, azim = azim)\n",
    "\n",
    "plt.savefig('./images/3D_TotalLight_' + fname + '.pdf', format='pdf',bbox_inches = 'tight', pad_inches = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "Z = tnumClu\n",
    "\n",
    "azim = 180+45\n",
    "elev = 30\n",
    "un = 1000\n",
    "\n",
    "fig = plt.figure(figsize = (12,8))\n",
    "ax  = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "ax.scatter(Yy.T,Xx.T, Z, c = 'r', marker = 'o')\n",
    "\n",
    "ax.set_xlabel('MinPoints',labelpad = 20, rotation=0)\n",
    "ax.set_ylabel('Eps',labelpad = 20)\n",
    "ax.set_zlabel('Total number of clusters', labelpad = 10, rotation = 90)\n",
    "ax.set_ylim(0,80)\n",
    "ax.set_xlim(0,300)\n",
    "ax.set_zlim(bottom = 0)\n",
    "ax.view_init(elev = elev, azim = azim)\n",
    "\n",
    "plt.savefig('./images/3D_TotalClu_' + fname + '.pdf', format='pdf',bbox_inches = 'tight', pad_inches = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "from matplotlib.ticker import LinearLocator, FormatStrFormatter\n",
    "import matplotlib.ticker as mticker\n",
    "#import numpy as np\n",
    "\n",
    "Z = tnumPix\n",
    "\n",
    "#pylab.rcParams['ytick.major.pad']='8'\n",
    "\n",
    "fig = plt.figure(figsize=(20,20))\n",
    "ax = fig.gca(projection='3d')\n",
    "\n",
    "# Plot the surface.\n",
    "\n",
    "surf = ax.plot_surface(Xx.T,Yy.T,Z,cmap='viridis')\n",
    "ax.set_xlabel('EPS parameter',labelpad = 20,rotation=-17)\n",
    "ax.set_ylabel('Min_Points parameter',labelpad = 20,rotation=90)\n",
    "\n",
    "ax.set_zlabel('Number of clusters [log]',labelpad = 60,rotation=0)\n",
    "ax.tick_params(axis='z', which='major', pad=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columnsT = [\"X\",\"Y\",\"Ls\",\"Image\",\"Tag\"]\n",
    "dftruth = pd.DataFrame(clutruth, columns = columnsT)\n",
    "\n",
    "columns = [\"Run\",\"Image\",\"Tag\",\"X\",\"Y\",\"Light\",\"Pedestal\"]\n",
    "dfi = pd.DataFrame(datai2DB, columns = columns)\n",
    "\n",
    "if flag_naive == True:\n",
    "    columns = [\"Run\",\"Image\",\"Tag\",\"X\",\"Y\",\"Light\",\"Pedestal\"]\n",
    "    dfn = pd.DataFrame(dataNaive, columns = columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Efficiency evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BACKUP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_colorpalette(idb):\n",
    "    palette = sns.color_palette('deep', np.unique(idb.labels_).max() + 1)\n",
    "    colors = [palette[x] if x >= 0 else (0.0, 0.0, 0.0) for x in idb.labels_]\n",
    "    return colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = points\n",
    "colorsI = get_colorpalette(clusters)\n",
    "colorsN = get_colorpalette(naive)\n",
    "\n",
    "\n",
    "## PLOT Noise Rejection\n",
    "fig, ax = plt.subplots(1,2,figsize=(16, 8), sharex=True, sharey=True)\n",
    "ax[0].invert_yaxis()\n",
    "\n",
    "ax[0].scatter(X[:, 1], X[:, 0], c=colorsI, **plot_kwds)\n",
    "ax[0].set_title(\"i2DBSCAN\")\n",
    "\n",
    "ax[1].scatter(X[:, 1], X[:, 0], c=colorsN, **plot_kwds)\n",
    "ax[1].set_title(\"Naive DBSCAN\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "th_image      = np.round(m_image + nsigma*s_image) # verficare con il np.round.... np.ceil\n",
    "th_image[:,:] = 102 # per imostare tutto a 101\n",
    "\n",
    "\n",
    "edges_image     = (truth[it][0] > th_image) & (truth[it][0] < cimax)\n",
    "rebin_image     = cy.rebin(truth[it][0], (rescale, rescale))\n",
    "rebin_th_image  = cy.rebin(th_image, (rescale, rescale))\n",
    "edges           = (rebin_image > rebin_th_image) & (rebin_image < cimax)         \n",
    "points          = np.array(np.nonzero(edges)).T.astype(float)\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=(7,7))\n",
    "\n",
    "plt.scatter(points[:, 1], points[:, 0],**plot_kwds)\n",
    "plt.xlim(0,511)\n",
    "plt.ylim(511,0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15,15))\n",
    "ax  = plt.gca()\n",
    "\n",
    "iax = ax.imshow(image,cmap=\"viridis\", vmin=85,vmax=130)\n",
    "ax.set_xlim(np.min(newX),np.max(newX))\n",
    "ax.set_ylim(np.max(newY),np.min(newY))\n",
    "ax.set_title(\"I%d Run%d + one random long track\" % (iTr, runI[0]))\n",
    "colorbar(iax)\n",
    "plt.show(block=False)\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To remove any NaN\n",
    "s_image[np.isnan(s_image)] = np.mean(s_image[~np.isnan(s_image)])\n",
    "m_image[np.isnan(m_image)] = np.mean(m_image[~np.isnan(m_image)])\n",
    "\n",
    "m_image[m_image > 101] = np.mean(m_image[m_image < 101])\n",
    "s_image[s_image > 4] = np.mean(s_image[s_image < 4])\n",
    "\n",
    "\n",
    "n_image = np.random.normal(m_image,s_image,[2048,2048])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15,15))\n",
    "ax  = plt.gca()\n",
    "\n",
    "iax = ax.imshow(n_image,cmap=\"viridis\", vmin=85,vmax=130)\n",
    "ax.set_xlim(0,2047)\n",
    "ax.set_ylim(2047,0)\n",
    "ax.set_title(\"Background Image\")\n",
    "colorbar(iax)\n",
    "plt.show(block=False)\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
